{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Standard_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpmvKzTKInvEP3P0V6pp0Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wE8RBc7GqqH"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXikC_Uz5eV2"
      },
      "source": [
        "try: \n",
        "    tpu = None\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError: \n",
        "    strategy = tf.distribute.MirroredStrategy() \n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OHw98VpUDyk"
      },
      "source": [
        "TARGET_DIM = (224, 224)\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg1-VWCOHSET"
      },
      "source": [
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    # Reserve 10% for validation and 10% for test\n",
        "    split=[\"train[:90%]\", \"train[90%:95%]\", \"train[95%:]\"],\n",
        "    as_supervised=True,  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g61V0KBwfI8"
      },
      "source": [
        "def preprocess_dataset(image, label):\n",
        "    image = tf.image.resize(image, (TARGET_DIM[0], TARGET_DIM[1]))\n",
        "    label = tf.one_hot(label, depth=2)\n",
        "    return (image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70-6QO3eri7D"
      },
      "source": [
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(BATCH_SIZE * 100)\n",
        "    .map(preprocess_dataset, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "validation_ds = (\n",
        "    validation_ds\n",
        "    .map(preprocess_dataset, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(preprocess_dataset, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb8WWT0Rvq-r"
      },
      "source": [
        "def get_model():\n",
        "    backbone = tf.keras.applications.DenseNet121(weights=None, include_top=True, classes=2)\n",
        "    backbone.trainable = True\n",
        "    \n",
        "    inputs = layers.Input((INP_DIM[0], INP_DIM[1], 3))\n",
        "    x = layers.experimental.preprocessing.Rescaling(scale=1./255)(inputs)\n",
        "    outputs = backbone(x)\n",
        "    outputs = layers.Activation(\"linear\", dtype=\"float32\")(outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPdhuyHN6DnC"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = get_model()\n",
        "    model.compile(loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "                optimizer=\"sgd\",\n",
        "                metrics=[\"accuracy\"])\n",
        "model.fit(train_ds,\n",
        "          validation_data=validation_ds,\n",
        "          epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGor7uS_6ejQ"
      },
      "source": [
        "with strategy.scope():\n",
        "    _, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n",
        "\n",
        "model.save(\"standard_densenet_model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}